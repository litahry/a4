{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d9cdbbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-3.2.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import logging\n",
    "from pyspark.sql.functions import col, sum as pyspark_sum, countDistinct\n",
    "from pyspark.sql.functions import to_timestamp\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.ml.stat import Correlation\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "import numpy as np\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col, unix_timestamp, hour, dayofmonth, month, year, to_timestamp\n",
    "\n",
    "# Create SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName('a4pt4') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a2d5161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing datasets as pyspark dataframe\n",
    "df = spark.read.format(\"csv\") \\\n",
    "             .option(\"header\", \"true\") \\\n",
    "             .option(\"inferSchema\", \"true\") \\\n",
    "             .load(\"joined04.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c77c64",
   "metadata": {},
   "source": [
    "### balance classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d502c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|music_effects|count|\n",
      "+-------------+-----+\n",
      "|            1|  524|\n",
      "|            3|  546|\n",
      "|            2|  542|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count the number of instances for each class\n",
    "class_counts = df.groupBy(\"music_effects\").count().collect()\n",
    "class_counts_dict = {row['music_effects']: row['count'] for row in class_counts}\n",
    "\n",
    "# Calculate the maximum class count\n",
    "max_count = max(class_counts_dict.values())\n",
    "\n",
    "# Define a function to balance the classes\n",
    "def balance_classes(df, class_counts, max_count):\n",
    "    sampled_dfs = []\n",
    "    for cls, count in class_counts.items():\n",
    "        if count < max_count:\n",
    "            fraction = max_count / count\n",
    "            sampled_df = df.filter(col(\"music_effects\") == cls).sample(withReplacement=True, fraction=fraction, seed=42)\n",
    "        else:\n",
    "            sampled_df = df.filter(col(\"music_effects\") == cls)\n",
    "        sampled_dfs.append(sampled_df)\n",
    "    return sampled_dfs\n",
    "\n",
    "# Apply the function to balance the classes\n",
    "sampled_dfs = balance_classes(df, class_counts_dict, max_count)\n",
    "balanced_df = sampled_dfs[0]\n",
    "for sampled_df in sampled_dfs[1:]:\n",
    "    balanced_df = balanced_df.union(sampled_df)\n",
    "\n",
    "# Verify the class distribution\n",
    "balanced_df.groupBy(\"music_effects\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19a21b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the balanced data into training and test sets of 80/70\n",
    "train_df, test_df = balanced_df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac6e0dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/23 16:57:49 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# List of categorical columns to be indexed\n",
    "categorical_columns = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "\n",
    "# Apply StringIndexer to each categorical column\n",
    "indexers = [StringIndexer(inputCol=column, outputCol=column + \"_indexed\").fit(train_df) for column in categorical_columns]\n",
    "\n",
    "# Apply the indexers to the data\n",
    "for indexer in indexers:\n",
    "    train_df = indexer.transform(train_df)\n",
    "    test_df = indexer.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f100dcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble features\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Define the feature columns, including indexed categorical columns\n",
    "indexed_feature_columns = [column + \"_indexed\" for column in categorical_columns]\n",
    "feature_columns = [col for col in df.columns if col not in [\"music_effects\", \"unique_id\", \"timestamp\", \"primary_streaming_service\", \"fav_genre\", \"age_bin\", \"hours_per_day_bin\", \"date\"]]\n",
    "all_feature_columns = feature_columns + indexed_feature_columns\n",
    "\n",
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=all_feature_columns, outputCol=\"features\")\n",
    "assembled_train_df = assembler.transform(train_df)\n",
    "assembled_test_df = assembler.transform(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "164109a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|             Feature|          Importance|\n",
      "+--------------------+--------------------+\n",
      "|                 age| 0.06974397782556455|\n",
      "|       hours_per_day|0.025105938131145717|\n",
      "|       while_working|0.015394188849801925|\n",
      "|                 bpm|0.033702806761998626|\n",
      "| frequency_classical|0.018046237426917053|\n",
      "|       frequency_edm|0.017206631106492364|\n",
      "|      frequency_folk|0.012569489745022778|\n",
      "|   frequency_hip_hop| 0.02030600602907475|\n",
      "|     frequency_k_pop|0.014668632534443882|\n",
      "|     frequency_latin| 0.02400958931664215|\n",
      "|      frequency_lofi| 0.01463393736941205|\n",
      "|     frequency_metal|0.024244694817012354|\n",
      "|       frequency_pop|0.014339816760348251|\n",
      "|       frequency_r&b|0.020400106660679374|\n",
      "|      frequency_rock| 0.01562155673091182|\n",
      "|frequency_video_g...| 0.01896755452941571|\n",
      "|             anxiety| 0.04548115727848281|\n",
      "|          depression| 0.12888820010794436|\n",
      "|            insomnia|0.022551935727659175|\n",
      "|                 ocd|0.022268605361756996|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define a RandomForest model\n",
    "rf = RandomForestClassifier(labelCol=\"music_effects\", featuresCol=\"features\", numTrees=100, maxBins=50)\n",
    "\n",
    "# Train the model\n",
    "rf_model = rf.fit(assembled_train_df)\n",
    "\n",
    "# Get feature importances\n",
    "importances = rf_model.featureImportances\n",
    "\n",
    "# Get feature names\n",
    "feature_names = assembler.getInputCols()\n",
    "\n",
    "# Combine feature names and importances into a list of tuples, converting importances to float\n",
    "data = [(feature, float(importance)) for feature, importance in zip(feature_names, importances.toArray())]\n",
    "\n",
    "# Create a PySpark DataFrame\n",
    "importance_df = spark.createDataFrame(data, [\"Feature\", \"Importance\"])\n",
    "\n",
    "# Filter features with importance greater than 0.01\n",
    "important_features_df = importance_df.filter(col(\"Importance\") > 0.01)\n",
    "\n",
    "# Show the information on the new dataset\n",
    "important_features_df.show()\n",
    "\n",
    "# Convert PySpark DataFrame to Pandas DataFrame\n",
    "importance_pdf = important_features_df.toPandas()\n",
    "\n",
    "# Plot feature importances\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(importance_pdf[\"Feature\"], importance_pdf[\"Importance\"], color='skyblue')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.title('Feature Importances')\n",
    "plt.gca().invert_yaxis()  # Invert y-axis to have the most important feature at the top\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04c3c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- hours_per_day: double (nullable = true)\n",
      " |-- while_working: integer (nullable = true)\n",
      " |-- bpm: double (nullable = true)\n",
      " |-- frequency_classical: integer (nullable = true)\n",
      " |-- frequency_edm: integer (nullable = true)\n",
      " |-- frequency_folk: integer (nullable = true)\n",
      " |-- frequency_hip_hop: integer (nullable = true)\n",
      " |-- frequency_latin: integer (nullable = true)\n",
      " |-- frequency_lofi: integer (nullable = true)\n",
      " |-- frequency_metal: integer (nullable = true)\n",
      " |-- frequency_pop: integer (nullable = true)\n",
      " |-- frequency_r&b: integer (nullable = true)\n",
      " |-- frequency_rock: integer (nullable = true)\n",
      " |-- frequency_video_game_music: integer (nullable = true)\n",
      " |-- anxiety: double (nullable = true)\n",
      " |-- depression: double (nullable = true)\n",
      " |-- insomnia: double (nullable = true)\n",
      " |-- ocd: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      " |-- primary_streaming_service: string (nullable = true)\n",
      " |-- fav_genre: string (nullable = true)\n",
      " |-- age_bin: string (nullable = true)\n",
      " |-- hours_per_day_bin: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- music_effects: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extracted features into new dataframe\n",
    "# List of important features to extract\n",
    "important_features = [\n",
    "    \"age\", \"hours_per_day\", \"while_working\", \"bpm\", \"frequency_classical\",\n",
    "    \"frequency_edm\", \"frequency_folk\", \"frequency_hip_hop\", \"frequency_latin\",\n",
    "    \"frequency_lofi\", \"frequency_metal\", \"frequency_pop\", \"frequency_r&b\",\n",
    "    \"frequency_rock\", \"frequency_video_game_music\", \"anxiety\", \"depression\",\n",
    "    \"insomnia\", \"ocd\", \"hour\", \"minute\", \"primary_streaming_service\",\n",
    "    \"fav_genre\", \"age_bin\", \"hours_per_day_bin\", \"date\"\n",
    "]\n",
    "\n",
    "# Add music_effects to the list of important features\n",
    "important_features.append(\"music_effects\")\n",
    "\n",
    "# Extract the important features from the original DataFrame\n",
    "extracted_df = df.select(*important_features)\n",
    "# Print schema to understand the structure\n",
    "extracted_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "195d5c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved at: 4extracted_df.csv\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Save DataFrame as CSV\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "file_path = \"4extracted_df.csv\"\n",
    "extracted_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(file_path)\n",
    "\n",
    "# Show the file path\n",
    "print(\"CSV file saved at:\", file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3cc8b4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Unable to infer schema for CSV. It must be specified manually.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparkSession\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# # Create a SparkSession\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# spark = SparkSession.builder \\\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#     .appName(\"Save and Read DataFrame as CSV\") \\\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Read the CSV file back into a Spark DataFrame\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m extracted_df \u001b[38;5;241m=\u001b[39m \u001b[43mspark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moption\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mheader\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Show the schema and first few rows of the read-back DataFrame\u001b[39;00m\n\u001b[1;32m     21\u001b[0m extracted_df\u001b[38;5;241m.\u001b[39mprintSchema()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/readwriter.py:410\u001b[0m, in \u001b[0;36mDataFrameReader.csv\u001b[0;34m(self, path, schema, sep, encoding, quote, escape, comment, header, inferSchema, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, nullValue, nanValue, positiveInf, negativeInf, dateFormat, timestampFormat, maxColumns, maxCharsPerColumn, maxMalformedLogPerPartition, mode, columnNameOfCorruptRecord, multiLine, charToEscapeQuoteEscaping, samplingRatio, enforceSchema, emptyValue, locale, lineSep, pathGlobFilter, recursiveFileLookup, modifiedBefore, modifiedAfter, unescapedQuoteHandling)\u001b[0m\n\u001b[1;32m    408\u001b[0m     path \u001b[38;5;241m=\u001b[39m [path]\n\u001b[1;32m    409\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(path) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[0;32m--> 410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_df(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jreader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_spark\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonUtils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoSeq\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, RDD):\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunc\u001b[39m(iterator):\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Unable to infer schema for CSV. It must be specified manually."
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Save and Read DataFrame as CSV\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Assuming extracted_df is already defined and you want to save it\n",
    "file_path = \"4extracted_df.csv\"\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "extracted_df.write.mode(\"overwrite\").option(\"header\", \"true\").csv(file_path)\n",
    "\n",
    "# Show the file path\n",
    "print(\"CSV file saved at:\", file_path)\n",
    "\n",
    "# Read the CSV file back into a Spark DataFrame\n",
    "extracted_df = spark.read.option(\"header\", \"true\").csv(file_path)\n",
    "\n",
    "# Show the schema and first few rows of the read-back DataFrame\n",
    "extracted_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise distributions of selected features \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Convert the PySpark DataFrame to a Pandas DataFrame for visualization\n",
    "pandas_df = df.select(important_features).toPandas()\n",
    "\n",
    "# Plot histograms of the features\n",
    "pandas_df.hist(figsize=(20, 15), bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9d2d5f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, log, sqrt\n",
    "from pyspark.sql import DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Function to calculate skewness and kurtosis\n",
    "def calculate_statistics(df: DataFrame, columns: list) -> pd.DataFrame:\n",
    "    stats = {}\n",
    "    for column in columns:\n",
    "        col_data = df.select(col(column)).toPandas()\n",
    "        stats[column] = {\n",
    "            'skewness': skew(col_data.dropna()),\n",
    "            'kurtosis': kurtosis(col_data.dropna())\n",
    "        }\n",
    "    return pd.DataFrame(stats).T\n",
    "\n",
    "# New features df\n",
    "df = extracted_df\n",
    "# List of string columns to be indexed\n",
    "string_cols = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "# Initialize StringIndexer for each string column with handleInvalid='keep'\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "\n",
    "# Apply StringIndexer to transform string columns into indexed columns\n",
    "pipeline_indexer = Pipeline(stages=indexers)\n",
    "df_indexed = pipeline_indexer.fit(df).transform(df)\n",
    "\n",
    "# Ensure all columns are correctly transformed\n",
    "def transform_columns(df: DataFrame, transformation_func, suffix: str) -> DataFrame:\n",
    "    transformed_cols = [transformation_func(col(c)).alias(f\"{c}_{suffix}\") for c in df.columns if c not in string_cols + ['music_effects']]\n",
    "    return df.select(['music_effects'] + [f\"{col}_indexed\" for col in string_cols] + transformed_cols)\n",
    "\n",
    "# Apply log and sqrt transformations\n",
    "df_log_transformed = transform_columns(df_indexed, lambda c: log(c + 1), 'log')\n",
    "df_sqrt_transformed = transform_columns(df_indexed, sqrt, 'sqrt')\n",
    "\n",
    "# Extract relevant columns for comparison\n",
    "numeric_columns = [col for col in df.columns if col not in string_cols + ['music_effects']]\n",
    "original_stats = calculate_statistics(df_indexed, numeric_columns)\n",
    "log_stats = calculate_statistics(df_log_transformed, [f\"{col}_log\" for col in numeric_columns])\n",
    "sqrt_stats = calculate_statistics(df_sqrt_transformed, [f\"{col}_sqrt\" for col in numeric_columns])\n",
    "\n",
    "# Print statistics\n",
    "print(\"Original Data Statistics:\")\n",
    "print(original_stats)\n",
    "print(\"\\nLog-Transformed Data Statistics:\")\n",
    "print(log_stats)\n",
    "print(\"\\nSquare Root-Transformed Data Statistics:\")\n",
    "print(sqrt_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad23410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, log, sqrt\n",
    "from pyspark.sql import DataFrame\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import skew, kurtosis, boxcox, yeojohnson\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Function to calculate skewness and kurtosis\n",
    "def calculate_statistics(df: DataFrame, columns: list) -> pd.DataFrame:\n",
    "    stats = {}\n",
    "    for column in columns:\n",
    "        col_data = df.select(col(column)).toPandas()\n",
    "        stats[column] = {\n",
    "            'skewness': skew(col_data.dropna()),\n",
    "            'kurtosis': kurtosis(col_data.dropna())\n",
    "        }\n",
    "    return pd.DataFrame(stats).T\n",
    "\n",
    "# New features df\n",
    "df = extracted_df\n",
    "# List of string columns to be indexed\n",
    "string_cols = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "# Initialize StringIndexer for each string column with handleInvalid='keep'\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "\n",
    "# Apply StringIndexer to transform string columns into indexed columns\n",
    "pipeline_indexer = Pipeline(stages=indexers)\n",
    "df_indexed = pipeline_indexer.fit(df).transform(df)\n",
    "\n",
    "# Ensure all columns are correctly transformed\n",
    "def transform_columns(df: DataFrame, transformation_func, suffix: str) -> DataFrame:\n",
    "    transformed_cols = [transformation_func(col(c)).alias(f\"{c}_{suffix}\") for c in df.columns if c not in string_cols + ['music_effects']]\n",
    "    return df.select(['music_effects'] + [f\"{col}_indexed\" for col in string_cols] + transformed_cols)\n",
    "\n",
    "# Apply log and sqrt transformations\n",
    "df_log_transformed = transform_columns(df_indexed, lambda c: log(c + 1), 'log')\n",
    "df_sqrt_transformed = transform_columns(df_indexed, sqrt, 'sqrt')\n",
    "\n",
    "# Apply Box-Cox and Yeo-Johnson transformations\n",
    "def apply_statistical_transformation(df: DataFrame, columns: list, method='boxcox') -> pd.DataFrame:\n",
    "    pandas_df = df.select(columns).toPandas()\n",
    "    transformed_data = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        if method == 'boxcox':\n",
    "            transformed_data[f\"{column}_boxcox\"] = boxcox(pandas_df[column] + 1)[0]  # boxcox requires positive values\n",
    "        elif method == 'yeojohnson':\n",
    "            transformed_data[f\"{column}_yeojohnson\"] = yeojohnson(pandas_df[column] + 1)[0]\n",
    "    return spark.createDataFrame(transformed_data)\n",
    "numeric_columns = [col for col in df.columns if col not in string_cols + ['music_effects']]\n",
    "boxcox_transformed_df = apply_statistical_transformation(df_indexed, numeric_columns, method='boxcox')\n",
    "yeojohnson_transformed_df = apply_statistical_transformation(df_indexed, numeric_columns, method='yeojohnson')\n",
    "\n",
    "# Calculate statistics for Box-Cox and Yeo-Johnson transformations\n",
    "boxcox_stats = calculate_statistics(boxcox_transformed_df, [f\"{col}_boxcox\" for col in numeric_columns])\n",
    "yeojohnson_stats = calculate_statistics(yeojohnson_transformed_df, [f\"{col}_yeojohnson\" for col in numeric_columns])\n",
    "\n",
    "# Print statistics\n",
    "print(\"Original Data Statistics:\")\n",
    "print(original_stats)\n",
    "print(\"\\nLog-Transformed Data Statistics:\")\n",
    "print(log_stats)\n",
    "print(\"\\nSquare Root-Transformed Data Statistics:\")\n",
    "print(sqrt_stats)\n",
    "print(\"\\nBox-Cox Transformed Data Statistics:\")\n",
    "print(boxcox_stats)\n",
    "print(\"\\nYeo-Johnson Transformed Data Statistics:\")\n",
    "print(yeojohnson_stats)\n",
    "\n",
    "# Function to visualize distributions before and after transformations\n",
    "def plot_distributions(original_df, transformed_df, transformation_name):\n",
    "    for column in numeric_columns:\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.histplot(original_df.select(col(column)).toPandas().dropna(), kde=True)\n",
    "        plt.title(f'Original: {column}')\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.histplot(transformed_df.select(col(f\"{column}_{transformation_name}\")).toPandas().dropna(), kde=True)\n",
    "        plt.title(f'{transformation_name}: {column}')\n",
    "        plt.show()\n",
    "\n",
    "# Plot distributions\n",
    "plot_distributions(df_indexed, df_log_transformed, 'log')\n",
    "plot_distributions(df_indexed, df_sqrt_transformed, 'sqrt')\n",
    "plot_distributions(df_indexed, boxcox_transformed_df, 'boxcox')\n",
    "plot_distributions(df_indexed, yeojohnson_transformed_df, 'yeojohnson')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11135f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyspark.sql.functions import col, log1p, sqrt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.types import DoubleType\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import yeojohnson, skew, kurtosis\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Function to calculate skewness and kurtosis\n",
    "def calculate_statistics(df: DataFrame, columns: list) -> pd.DataFrame:\n",
    "    stats = {}\n",
    "    for column in columns:\n",
    "        col_data = df.select(col(column)).toPandas()\n",
    "        stats[column] = {\n",
    "            'skewness': skew(col_data.dropna()),\n",
    "            'kurtosis': kurtosis(col_data.dropna())\n",
    "        }\n",
    "    return pd.DataFrame(stats).T\n",
    "\n",
    "# Function to apply Yeo-Johnson transformation\n",
    "def apply_yeojohnson(df: DataFrame, columns: list) -> DataFrame:\n",
    "    pandas_df = df.select(columns).toPandas()\n",
    "    transformed_data = pd.DataFrame()\n",
    "    for column in columns:\n",
    "        transformed_data[f\"{column}_yeojohnson\"] = yeojohnson(pandas_df[column])[0]\n",
    "    return spark.createDataFrame(transformed_data)\n",
    "\n",
    "# Ensure numeric columns are of DoubleType for transformations\n",
    "df = extracted_df\n",
    "df = df.withColumn(\"age\", col(\"age\").cast(DoubleType()))\\\n",
    "       .withColumn(\"hours_per_day\", col(\"hours_per_day\").cast(DoubleType()))\\\n",
    "       .withColumn(\"bpm\", col(\"bpm\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_classical\", col(\"frequency_classical\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_edm\", col(\"frequency_edm\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_folk\", col(\"frequency_folk\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_hip_hop\", col(\"frequency_hip_hop\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_latin\", col(\"frequency_latin\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_lofi\", col(\"frequency_lofi\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_metal\", col(\"frequency_metal\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_pop\", col(\"frequency_pop\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_r&b\", col(\"frequency_r&b\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_rock\", col(\"frequency_rock\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_video_game_music\", col(\"frequency_video_game_music\").cast(DoubleType()))\\\n",
    "       .withColumn(\"anxiety\", col(\"anxiety\").cast(DoubleType()))\\\n",
    "       .withColumn(\"depression\", col(\"depression\").cast(DoubleType()))\\\n",
    "       .withColumn(\"insomnia\", col(\"insomnia\").cast(DoubleType()))\\\n",
    "       .withColumn(\"ocd\", col(\"ocd\").cast(DoubleType()))\n",
    "\n",
    "# List of string columns to be indexed\n",
    "string_cols = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "# Initialize StringIndexer for each string column with handleInvalid='keep'\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "\n",
    "# Apply StringIndexer to transform string columns into indexed columns\n",
    "pipeline_indexer = Pipeline(stages=indexers)\n",
    "df_indexed = pipeline_indexer.fit(df).transform(df)\n",
    "\n",
    "# Ensure all columns are correctly transformed\n",
    "def transform_columns(df: DataFrame, transformation_func, suffix: str) -> DataFrame:\n",
    "    transformed_cols = [transformation_func(col(c)).alias(f\"{c}_{suffix}\") for c in df.columns if c not in string_cols + ['music_effects']]\n",
    "    return df.select(['music_effects'] + [f\"{col}_indexed\" for col in string_cols] + transformed_cols)\n",
    "\n",
    "# Apply log1p and sqrt transformations\n",
    "df_log1p_transformed = transform_columns(df_indexed, log1p, 'log1p')\n",
    "df_sqrt_transformed = transform_columns(df_indexed, sqrt, 'sqrt')\n",
    "\n",
    "# Apply Yeo-Johnson transformation\n",
    "yeojohnson_transformed_df = apply_yeojohnson(df_indexed, numeric_columns)\n",
    "\n",
    "# Combine the transformed columns\n",
    "transformed_df = df_log1p_transformed.join(df_sqrt_transformed, \"music_effects\", \"outer\")\n",
    "transformed_df = transformed_df.join(yeojohnson_transformed_df, \"music_effects\", \"outer\")\n",
    "\n",
    "# Ensure to add back the indexed string columns and music_effects\n",
    "transformed_df = df_indexed.select(['music_effects'] + [f\"{col}_indexed\" for col in string_cols]).join(transformed_df, \"music_effects\", \"outer\")\n",
    "\n",
    "# Extract relevant columns for comparison\n",
    "numeric_columns = [col for col in df.columns if col not in string_cols + ['music_effects']]\n",
    "original_stats = calculate_statistics(df_indexed, numeric_columns)\n",
    "log1p_stats = calculate_statistics(df_log1p_transformed, [f\"{col}_log1p\" for col in numeric_columns])\n",
    "sqrt_stats = calculate_statistics(df_sqrt_transformed, [f\"{col}_sqrt\" for col in numeric_columns])\n",
    "yeojohnson_stats = calculate_statistics(yeojohnson_transformed_df, [f\"{col}_yeojohnson\" for col in numeric_columns])\n",
    "\n",
    "# Print statistics\n",
    "print(\"Original Data Statistics:\")\n",
    "print(original_stats)\n",
    "print(\"\\nLog1p-Transformed Data Statistics:\")\n",
    "print(log1p_stats)\n",
    "print(\"\\nSquare Root-Transformed Data Statistics:\")\n",
    "print(sqrt_stats)\n",
    "print(\"\\nYeo-Johnson Transformed Data Statistics:\")\n",
    "print(yeojohnson_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba73db7a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data Statistics:\n",
      "                                           skewness                kurtosis\n",
      "age                            [1.8895857044177138]    [3.6057917718498285]\n",
      "while_working                 [-1.4126448280440336]  [-0.00443458980044209]\n",
      "frequency_classical           [0.20584697166393687]   [-0.9837042719813489]\n",
      "frequency_edm                  [0.5950379557774494]   [-0.9230320719250535]\n",
      "frequency_folk                 [0.5988432284183117]   [-0.8154313530521917]\n",
      "frequency_hip_hop              [0.0876266545078173]   [-1.1425673133392718]\n",
      "frequency_latin                [1.2665004966342674]    [0.5939484932438441]\n",
      "frequency_lofi                 [0.4968070382788795]   [-0.9731223155493645]\n",
      "frequency_metal                [0.3831478025447569]   [-1.2720957706799887]\n",
      "frequency_pop                 [-0.6336414089562802]   [-0.5574416487122815]\n",
      "frequency_r&b                 [0.28379711011024733]    [-1.163480028265298]\n",
      "frequency_rock                [-0.8235623678229196]   [-0.5425774097429183]\n",
      "frequency_video_game_music    [0.27549000404578317]   [-1.2082797392713538]\n",
      "anxiety                      [-0.42446436357004813]   [-0.7563741905228039]\n",
      "depression                  [-0.035481577269063355]    [-1.156024521569584]\n",
      "insomnia                       [0.4108447529195915]   [-1.0187136406006956]\n",
      "ocd                            [0.9595611682405449]  [-0.13085678996705408]\n",
      "hour                          [-0.4615732614650024]   [-0.8647460500570836]\n",
      "minute                        [0.10702636327113456]   [-1.2207232942872703]\n",
      "hours_per_day                   [1.516473713303821]    [2.4660649929599288]\n",
      "bpm                            [0.5779459632141106]  [-0.12198299206489782]\n",
      "\n",
      "Yeo-Johnson Transformed Data Statistics:\n",
      "                                                      skewness  \\\n",
      "age_yeojohnson                           [0.05298432369992063]   \n",
      "while_working_yeojohnson                 [-1.4126448280440336]   \n",
      "frequency_classical_yeojohnson          [-0.04592346970162783]   \n",
      "frequency_edm_yeojohnson                 [0.11237918412849661]   \n",
      "frequency_folk_yeojohnson                 [0.0879077002960638]   \n",
      "frequency_hip_hop_yeojohnson            [-0.07514083888632163]   \n",
      "frequency_latin_yeojohnson                [0.5136388930827955]   \n",
      "frequency_lofi_yeojohnson                [0.05669428258971588]   \n",
      "frequency_metal_yeojohnson               [0.03549608172147369]   \n",
      "frequency_pop_yeojohnson                [-0.23835718599925365]   \n",
      "frequency_r&b_yeojohnson               [-0.019369374700395594]   \n",
      "frequency_rock_yeojohnson                [-0.3831707478028229]   \n",
      "frequency_video_game_music_yeojohnson  [-0.017504889098493598]   \n",
      "anxiety_yeojohnson                       [-0.2739507982741104]   \n",
      "depression_yeojohnson                    [-0.2285749184863265]   \n",
      "insomnia_yeojohnson                     [-0.12344303416294185]   \n",
      "ocd_yeojohnson                           [0.04228823496005337]   \n",
      "hour_yeojohnson                         [-0.37954302932346706]   \n",
      "minute_yeojohnson                         [-0.235689025585104]   \n",
      "\n",
      "                                                       kurtosis  \n",
      "age_yeojohnson                           [-0.04872245062326064]  \n",
      "while_working_yeojohnson               [-0.0044345898004429785]  \n",
      "frequency_classical_yeojohnson            [-1.0486275331514687]  \n",
      "frequency_edm_yeojohnson                  [-1.5441360902652828]  \n",
      "frequency_folk_yeojohnson                  [-1.466043855951881]  \n",
      "frequency_hip_hop_yeojohnson              [-1.1770646470009092]  \n",
      "frequency_latin_yeojohnson                [-1.6170733608035095]  \n",
      "frequency_lofi_yeojohnson                  [-1.452229645202718]  \n",
      "frequency_metal_yeojohnson                [-1.4942852951039216]  \n",
      "frequency_pop_yeojohnson                  [-1.1959429132773645]  \n",
      "frequency_r&b_yeojohnson                  [-1.3358662767221992]  \n",
      "frequency_rock_yeojohnson                 [-1.2868923547117026]  \n",
      "frequency_video_game_music_yeojohnson     [-1.3873858563703259]  \n",
      "anxiety_yeojohnson                        [-0.9016211134394347]  \n",
      "depression_yeojohnson                      [-1.092618271014386]  \n",
      "insomnia_yeojohnson                        [-1.245352100374066]  \n",
      "ocd_yeojohnson                            [-1.4522150358102166]  \n",
      "hour_yeojohnson                           [-0.9540505559495824]  \n",
      "minute_yeojohnson                         [-1.0708321218693158]  \n",
      "\n",
      "Box-Cox Transformed Data Statistics:\n",
      "                                       skewness                kurtosis\n",
      "hours_per_day_boxcox      [0.01010231728563761]   [-0.3378224703248329]\n",
      "bpm_boxcox            [-0.00048285996920044877]  [-0.15030189094785307]\n",
      "Combined Statistics:\n",
      "                                                      skewness  \\\n",
      "age                                       [1.8895857044177138]   \n",
      "while_working                            [-1.4126448280440336]   \n",
      "frequency_classical                      [0.20584697166393687]   \n",
      "frequency_edm                             [0.5950379557774494]   \n",
      "frequency_folk                            [0.5988432284183117]   \n",
      "frequency_hip_hop                         [0.0876266545078173]   \n",
      "frequency_latin                           [1.2665004966342674]   \n",
      "frequency_lofi                            [0.4968070382788795]   \n",
      "frequency_metal                           [0.3831478025447569]   \n",
      "frequency_pop                            [-0.6336414089562802]   \n",
      "frequency_r&b                            [0.28379711011024733]   \n",
      "frequency_rock                           [-0.8235623678229196]   \n",
      "frequency_video_game_music               [0.27549000404578317]   \n",
      "anxiety                                 [-0.42446436357004813]   \n",
      "depression                             [-0.035481577269063355]   \n",
      "insomnia                                  [0.4108447529195915]   \n",
      "ocd                                       [0.9595611682405449]   \n",
      "hour                                     [-0.4615732614650024]   \n",
      "minute                                   [0.10702636327113456]   \n",
      "hours_per_day                              [1.516473713303821]   \n",
      "bpm                                       [0.5779459632141106]   \n",
      "age_yeojohnson                                             NaN   \n",
      "while_working_yeojohnson                                   NaN   \n",
      "frequency_classical_yeojohnson                             NaN   \n",
      "frequency_edm_yeojohnson                                   NaN   \n",
      "frequency_folk_yeojohnson                                  NaN   \n",
      "frequency_hip_hop_yeojohnson                               NaN   \n",
      "frequency_latin_yeojohnson                                 NaN   \n",
      "frequency_lofi_yeojohnson                                  NaN   \n",
      "frequency_metal_yeojohnson                                 NaN   \n",
      "frequency_pop_yeojohnson                                   NaN   \n",
      "frequency_r&b_yeojohnson                                   NaN   \n",
      "frequency_rock_yeojohnson                                  NaN   \n",
      "frequency_video_game_music_yeojohnson                      NaN   \n",
      "anxiety_yeojohnson                                         NaN   \n",
      "depression_yeojohnson                                      NaN   \n",
      "insomnia_yeojohnson                                        NaN   \n",
      "ocd_yeojohnson                                             NaN   \n",
      "hour_yeojohnson                                            NaN   \n",
      "minute_yeojohnson                                          NaN   \n",
      "hours_per_day_boxcox                                       NaN   \n",
      "bpm_boxcox                                                 NaN   \n",
      "\n",
      "                                                     kurtosis  \\\n",
      "age                                      [3.6057917718498285]   \n",
      "while_working                          [-0.00443458980044209]   \n",
      "frequency_classical                     [-0.9837042719813489]   \n",
      "frequency_edm                           [-0.9230320719250535]   \n",
      "frequency_folk                          [-0.8154313530521917]   \n",
      "frequency_hip_hop                       [-1.1425673133392718]   \n",
      "frequency_latin                          [0.5939484932438441]   \n",
      "frequency_lofi                          [-0.9731223155493645]   \n",
      "frequency_metal                         [-1.2720957706799887]   \n",
      "frequency_pop                           [-0.5574416487122815]   \n",
      "frequency_r&b                            [-1.163480028265298]   \n",
      "frequency_rock                          [-0.5425774097429183]   \n",
      "frequency_video_game_music              [-1.2082797392713538]   \n",
      "anxiety                                 [-0.7563741905228039]   \n",
      "depression                               [-1.156024521569584]   \n",
      "insomnia                                [-1.0187136406006956]   \n",
      "ocd                                    [-0.13085678996705408]   \n",
      "hour                                    [-0.8647460500570836]   \n",
      "minute                                  [-1.2207232942872703]   \n",
      "hours_per_day                            [2.4660649929599288]   \n",
      "bpm                                    [-0.12198299206489782]   \n",
      "age_yeojohnson                                            NaN   \n",
      "while_working_yeojohnson                                  NaN   \n",
      "frequency_classical_yeojohnson                            NaN   \n",
      "frequency_edm_yeojohnson                                  NaN   \n",
      "frequency_folk_yeojohnson                                 NaN   \n",
      "frequency_hip_hop_yeojohnson                              NaN   \n",
      "frequency_latin_yeojohnson                                NaN   \n",
      "frequency_lofi_yeojohnson                                 NaN   \n",
      "frequency_metal_yeojohnson                                NaN   \n",
      "frequency_pop_yeojohnson                                  NaN   \n",
      "frequency_r&b_yeojohnson                                  NaN   \n",
      "frequency_rock_yeojohnson                                 NaN   \n",
      "frequency_video_game_music_yeojohnson                     NaN   \n",
      "anxiety_yeojohnson                                        NaN   \n",
      "depression_yeojohnson                                     NaN   \n",
      "insomnia_yeojohnson                                       NaN   \n",
      "ocd_yeojohnson                                            NaN   \n",
      "hour_yeojohnson                                           NaN   \n",
      "minute_yeojohnson                                         NaN   \n",
      "hours_per_day_boxcox                                      NaN   \n",
      "bpm_boxcox                                                NaN   \n",
      "\n",
      "                                                      skewness  \\\n",
      "age                                                        NaN   \n",
      "while_working                                              NaN   \n",
      "frequency_classical                                        NaN   \n",
      "frequency_edm                                              NaN   \n",
      "frequency_folk                                             NaN   \n",
      "frequency_hip_hop                                          NaN   \n",
      "frequency_latin                                            NaN   \n",
      "frequency_lofi                                             NaN   \n",
      "frequency_metal                                            NaN   \n",
      "frequency_pop                                              NaN   \n",
      "frequency_r&b                                              NaN   \n",
      "frequency_rock                                             NaN   \n",
      "frequency_video_game_music                                 NaN   \n",
      "anxiety                                                    NaN   \n",
      "depression                                                 NaN   \n",
      "insomnia                                                   NaN   \n",
      "ocd                                                        NaN   \n",
      "hour                                                       NaN   \n",
      "minute                                                     NaN   \n",
      "hours_per_day                                              NaN   \n",
      "bpm                                                        NaN   \n",
      "age_yeojohnson                           [0.05298432369992063]   \n",
      "while_working_yeojohnson                 [-1.4126448280440336]   \n",
      "frequency_classical_yeojohnson          [-0.04592346970162783]   \n",
      "frequency_edm_yeojohnson                 [0.11237918412849661]   \n",
      "frequency_folk_yeojohnson                 [0.0879077002960638]   \n",
      "frequency_hip_hop_yeojohnson            [-0.07514083888632163]   \n",
      "frequency_latin_yeojohnson                [0.5136388930827955]   \n",
      "frequency_lofi_yeojohnson                [0.05669428258971588]   \n",
      "frequency_metal_yeojohnson               [0.03549608172147369]   \n",
      "frequency_pop_yeojohnson                [-0.23835718599925365]   \n",
      "frequency_r&b_yeojohnson               [-0.019369374700395594]   \n",
      "frequency_rock_yeojohnson                [-0.3831707478028229]   \n",
      "frequency_video_game_music_yeojohnson  [-0.017504889098493598]   \n",
      "anxiety_yeojohnson                       [-0.2739507982741104]   \n",
      "depression_yeojohnson                    [-0.2285749184863265]   \n",
      "insomnia_yeojohnson                     [-0.12344303416294185]   \n",
      "ocd_yeojohnson                           [0.04228823496005337]   \n",
      "hour_yeojohnson                         [-0.37954302932346706]   \n",
      "minute_yeojohnson                         [-0.235689025585104]   \n",
      "hours_per_day_boxcox                                       NaN   \n",
      "bpm_boxcox                                                 NaN   \n",
      "\n",
      "                                                       kurtosis  \\\n",
      "age                                                         NaN   \n",
      "while_working                                               NaN   \n",
      "frequency_classical                                         NaN   \n",
      "frequency_edm                                               NaN   \n",
      "frequency_folk                                              NaN   \n",
      "frequency_hip_hop                                           NaN   \n",
      "frequency_latin                                             NaN   \n",
      "frequency_lofi                                              NaN   \n",
      "frequency_metal                                             NaN   \n",
      "frequency_pop                                               NaN   \n",
      "frequency_r&b                                               NaN   \n",
      "frequency_rock                                              NaN   \n",
      "frequency_video_game_music                                  NaN   \n",
      "anxiety                                                     NaN   \n",
      "depression                                                  NaN   \n",
      "insomnia                                                    NaN   \n",
      "ocd                                                         NaN   \n",
      "hour                                                        NaN   \n",
      "minute                                                      NaN   \n",
      "hours_per_day                                               NaN   \n",
      "bpm                                                         NaN   \n",
      "age_yeojohnson                           [-0.04872245062326064]   \n",
      "while_working_yeojohnson               [-0.0044345898004429785]   \n",
      "frequency_classical_yeojohnson            [-1.0486275331514687]   \n",
      "frequency_edm_yeojohnson                  [-1.5441360902652828]   \n",
      "frequency_folk_yeojohnson                  [-1.466043855951881]   \n",
      "frequency_hip_hop_yeojohnson              [-1.1770646470009092]   \n",
      "frequency_latin_yeojohnson                [-1.6170733608035095]   \n",
      "frequency_lofi_yeojohnson                  [-1.452229645202718]   \n",
      "frequency_metal_yeojohnson                [-1.4942852951039216]   \n",
      "frequency_pop_yeojohnson                  [-1.1959429132773645]   \n",
      "frequency_r&b_yeojohnson                  [-1.3358662767221992]   \n",
      "frequency_rock_yeojohnson                 [-1.2868923547117026]   \n",
      "frequency_video_game_music_yeojohnson     [-1.3873858563703259]   \n",
      "anxiety_yeojohnson                        [-0.9016211134394347]   \n",
      "depression_yeojohnson                      [-1.092618271014386]   \n",
      "insomnia_yeojohnson                        [-1.245352100374066]   \n",
      "ocd_yeojohnson                            [-1.4522150358102166]   \n",
      "hour_yeojohnson                           [-0.9540505559495824]   \n",
      "minute_yeojohnson                         [-1.0708321218693158]   \n",
      "hours_per_day_boxcox                                        NaN   \n",
      "bpm_boxcox                                                  NaN   \n",
      "\n",
      "                                                        skewness  \\\n",
      "age                                                          NaN   \n",
      "while_working                                                NaN   \n",
      "frequency_classical                                          NaN   \n",
      "frequency_edm                                                NaN   \n",
      "frequency_folk                                               NaN   \n",
      "frequency_hip_hop                                            NaN   \n",
      "frequency_latin                                              NaN   \n",
      "frequency_lofi                                               NaN   \n",
      "frequency_metal                                              NaN   \n",
      "frequency_pop                                                NaN   \n",
      "frequency_r&b                                                NaN   \n",
      "frequency_rock                                               NaN   \n",
      "frequency_video_game_music                                   NaN   \n",
      "anxiety                                                      NaN   \n",
      "depression                                                   NaN   \n",
      "insomnia                                                     NaN   \n",
      "ocd                                                          NaN   \n",
      "hour                                                         NaN   \n",
      "minute                                                       NaN   \n",
      "hours_per_day                                                NaN   \n",
      "bpm                                                          NaN   \n",
      "age_yeojohnson                                               NaN   \n",
      "while_working_yeojohnson                                     NaN   \n",
      "frequency_classical_yeojohnson                               NaN   \n",
      "frequency_edm_yeojohnson                                     NaN   \n",
      "frequency_folk_yeojohnson                                    NaN   \n",
      "frequency_hip_hop_yeojohnson                                 NaN   \n",
      "frequency_latin_yeojohnson                                   NaN   \n",
      "frequency_lofi_yeojohnson                                    NaN   \n",
      "frequency_metal_yeojohnson                                   NaN   \n",
      "frequency_pop_yeojohnson                                     NaN   \n",
      "frequency_r&b_yeojohnson                                     NaN   \n",
      "frequency_rock_yeojohnson                                    NaN   \n",
      "frequency_video_game_music_yeojohnson                        NaN   \n",
      "anxiety_yeojohnson                                           NaN   \n",
      "depression_yeojohnson                                        NaN   \n",
      "insomnia_yeojohnson                                          NaN   \n",
      "ocd_yeojohnson                                               NaN   \n",
      "hour_yeojohnson                                              NaN   \n",
      "minute_yeojohnson                                            NaN   \n",
      "hours_per_day_boxcox                       [0.01010231728563761]   \n",
      "bpm_boxcox                             [-0.00048285996920044877]   \n",
      "\n",
      "                                                     kurtosis  \n",
      "age                                                       NaN  \n",
      "while_working                                             NaN  \n",
      "frequency_classical                                       NaN  \n",
      "frequency_edm                                             NaN  \n",
      "frequency_folk                                            NaN  \n",
      "frequency_hip_hop                                         NaN  \n",
      "frequency_latin                                           NaN  \n",
      "frequency_lofi                                            NaN  \n",
      "frequency_metal                                           NaN  \n",
      "frequency_pop                                             NaN  \n",
      "frequency_r&b                                             NaN  \n",
      "frequency_rock                                            NaN  \n",
      "frequency_video_game_music                                NaN  \n",
      "anxiety                                                   NaN  \n",
      "depression                                                NaN  \n",
      "insomnia                                                  NaN  \n",
      "ocd                                                       NaN  \n",
      "hour                                                      NaN  \n",
      "minute                                                    NaN  \n",
      "hours_per_day                                             NaN  \n",
      "bpm                                                       NaN  \n",
      "age_yeojohnson                                            NaN  \n",
      "while_working_yeojohnson                                  NaN  \n",
      "frequency_classical_yeojohnson                            NaN  \n",
      "frequency_edm_yeojohnson                                  NaN  \n",
      "frequency_folk_yeojohnson                                 NaN  \n",
      "frequency_hip_hop_yeojohnson                              NaN  \n",
      "frequency_latin_yeojohnson                                NaN  \n",
      "frequency_lofi_yeojohnson                                 NaN  \n",
      "frequency_metal_yeojohnson                                NaN  \n",
      "frequency_pop_yeojohnson                                  NaN  \n",
      "frequency_r&b_yeojohnson                                  NaN  \n",
      "frequency_rock_yeojohnson                                 NaN  \n",
      "frequency_video_game_music_yeojohnson                     NaN  \n",
      "anxiety_yeojohnson                                        NaN  \n",
      "depression_yeojohnson                                     NaN  \n",
      "insomnia_yeojohnson                                       NaN  \n",
      "ocd_yeojohnson                                            NaN  \n",
      "hour_yeojohnson                                           NaN  \n",
      "minute_yeojohnson                                         NaN  \n",
      "hours_per_day_boxcox                    [-0.3378224703248329]  \n",
      "bpm_boxcox                             [-0.15030189094785307]  \n"
     ]
    }
   ],
   "source": [
    "#4.2 transformation\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import yeojohnson, boxcox, skew, kurtosis\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Function to calculate skewness and kurtosis\n",
    "def calculate_statistics(df, columns):\n",
    "    stats = {}\n",
    "    for column in columns:\n",
    "        col_data = df.select(col(column)).toPandas()\n",
    "        stats[column] = {\n",
    "            'skewness': skew(col_data.dropna()),\n",
    "            'kurtosis': kurtosis(col_data.dropna())\n",
    "        }\n",
    "    return pd.DataFrame(stats).T\n",
    "\n",
    "# Function to apply Yeo-Johnson transformation\n",
    "def apply_yeojohnson(df, columns):\n",
    "    pandas_df = df.select(columns + ['music_effects']).toPandas()\n",
    "    transformed_data = pd.DataFrame()\n",
    "    transformed_data['music_effects'] = pandas_df['music_effects']\n",
    "    for column in columns:\n",
    "        transformed_data[f\"{column}_yeojohnson\"] = yeojohnson(pandas_df[column])[0]\n",
    "    return spark.createDataFrame(transformed_data)\n",
    "\n",
    "# Function to apply Box-Cox transformation\n",
    "def apply_boxcox(df, columns):\n",
    "    pandas_df = df.select(columns + ['music_effects']).toPandas()\n",
    "    transformed_data = pd.DataFrame()\n",
    "    transformed_data['music_effects'] = pandas_df['music_effects']\n",
    "    for column in columns:\n",
    "        transformed_data[f\"{column}_boxcox\"], _ = boxcox(pandas_df[column] + 1)  # Adding 1 to ensure all values are positive\n",
    "    return spark.createDataFrame(transformed_data)\n",
    "\n",
    "# Ensure numeric columns are of DoubleType for transformations\n",
    "df = extracted_df\n",
    "df = df.withColumn(\"age\", col(\"age\").cast(DoubleType()))\\\n",
    "       .withColumn(\"hours_per_day\", col(\"hours_per_day\").cast(DoubleType()))\\\n",
    "       .withColumn(\"bpm\", col(\"bpm\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_classical\", col(\"frequency_classical\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_edm\", col(\"frequency_edm\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_folk\", col(\"frequency_folk\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_hip_hop\", col(\"frequency_hip_hop\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_latin\", col(\"frequency_latin\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_lofi\", col(\"frequency_lofi\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_metal\", col(\"frequency_metal\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_pop\", col(\"frequency_pop\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_r&b\", col(\"frequency_r&b\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_rock\", col(\"frequency_rock\").cast(DoubleType()))\\\n",
    "       .withColumn(\"frequency_video_game_music\", col(\"frequency_video_game_music\").cast(DoubleType()))\\\n",
    "       .withColumn(\"anxiety\", col(\"anxiety\").cast(IntegerType()))\\\n",
    "       .withColumn(\"depression\", col(\"depression\").cast(IntegerType()))\\\n",
    "       .withColumn(\"insomnia\", col(\"insomnia\").cast(IntegerType()))\\\n",
    "       .withColumn(\"ocd\", col(\"ocd\").cast(IntegerType()))\\\n",
    "       .withColumn(\"music_effects\", col(\"music_effects\").cast(IntegerType()))\n",
    "\n",
    "# List of string columns to be indexed\n",
    "string_cols = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "# Initialize StringIndexer for each string column with handleInvalid='keep'\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "\n",
    "# Apply StringIndexer to transform string columns into indexed columns\n",
    "pipeline_indexer = Pipeline(stages=indexers)\n",
    "df_indexed = pipeline_indexer.fit(df).transform(df)\n",
    "\n",
    "# Apply Yeo-Johnson transformation to the relevant numeric columns\n",
    "numeric_columns = [col for col in df.columns if col not in string_cols + ['music_effects', 'hours_per_day', 'bpm']]\n",
    "yeojohnson_transformed_df = apply_yeojohnson(df_indexed, numeric_columns)\n",
    "\n",
    "# Apply Box-Cox transformation to hours_per_day and bpm\n",
    "boxcox_transformed_df = apply_boxcox(df_indexed, ['hours_per_day', 'bpm'])\n",
    "\n",
    "# Calculate statistics\n",
    "original_stats = calculate_statistics(df_indexed, numeric_columns + ['hours_per_day', 'bpm'])\n",
    "yeojohnson_stats = calculate_statistics(yeojohnson_transformed_df, [f\"{col}_yeojohnson\" for col in numeric_columns])\n",
    "boxcox_stats = calculate_statistics(boxcox_transformed_df, ['hours_per_day_boxcox', 'bpm_boxcox'])\n",
    "\n",
    "# Print statistics\n",
    "print(\"Original Data Statistics:\")\n",
    "print(original_stats)\n",
    "print(\"\\nYeo-Johnson Transformed Data Statistics:\")\n",
    "print(yeojohnson_stats)\n",
    "print(\"\\nBox-Cox Transformed Data Statistics:\")\n",
    "print(boxcox_stats)\n",
    "\n",
    "# Concatenate statistics dataframes\n",
    "combined_stats = pd.concat([original_stats, yeojohnson_stats, boxcox_stats], axis=1)\n",
    "\n",
    "# Print combined statistics\n",
    "print(\"Combined Statistics:\")\n",
    "print(combined_stats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bce92c4",
   "metadata": {},
   "source": [
    "### 4.2 joining back the transfomed data together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aff9adcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------------+-----+-------------------+-------------+--------------+-----------------+---------------+--------------+---------------+-------------+-------------+--------------+--------------------------+-------+----------+--------+---+----+------+-------------------------+----------------+-------+-----------------+----------+-------------+\n",
      "|age|hours_per_day|while_working|  bpm|frequency_classical|frequency_edm|frequency_folk|frequency_hip_hop|frequency_latin|frequency_lofi|frequency_metal|frequency_pop|frequency_r&b|frequency_rock|frequency_video_game_music|anxiety|depression|insomnia|ocd|hour|minute|primary_streaming_service|       fav_genre|age_bin|hours_per_day_bin|      date|music_effects|\n",
      "+---+-------------+-------------+-----+-------------------+-------------+--------------+-----------------+---------------+--------------+---------------+-------------+-------------+--------------+--------------------------+-------+----------+--------+---+----+------+-------------------------+----------------+-------+-----------------+----------+-------------+\n",
      "| 18|          3.0|            1|156.0|                  2|            2|             1|                3|              4|             2|              1|            4|            3|             1|                         3|    3.0|       0.0|     1.0|0.0|  19|    29|                  spotify|           latin|  16-20|              2-3|2022-08-27|            3|\n",
      "| 18|          1.5|            1|119.0|                  3|            1|             2|                2|              3|             2|              1|            3|            3|             4|                         2|    7.0|       2.0|     2.0|1.0|  19|    57|                  pandora|            rock|  16-20|              1-2|2022-08-27|            3|\n",
      "| 18|          4.0|            0|132.0|                  1|            4|             1|                2|              1|             3|              3|            2|            1|             2|                         4|    7.0|       7.0|    10.0|2.0|  21|    28|                  spotify|video game music|  16-20|              3-4|2022-08-27|            2|\n",
      "| 18|          2.5|            1| 84.0|                  3|            1|             2|                1|              4|             3|              1|            3|            3|             1|                         1|    9.0|       7.0|     3.0|3.0|  21|    40|            youtube music|            jazz|  16-20|              2-3|2022-08-27|            3|\n",
      "| 18|          4.0|            1|107.0|                  1|            2|             1|                4|              3|             3|              1|            3|            4|             1|                         2|    7.0|       2.0|     5.0|9.0|  21|    54|                  spotify|             r&b|  16-20|              3-4|2022-08-27|            3|\n",
      "| 18|          5.0|            1| 86.0|                  2|            1|             1|                3|              2|             4|              2|            4|            4|             4|                         1|    8.0|       8.0|     7.0|7.0|  21|    56|                  spotify|            jazz|  16-20|              4-5|2022-08-27|            3|\n",
      "| 18|          3.0|            1| 66.0|                  3|            2|             3|                2|              2|             2|              2|            2|            2|             1|                         3|    4.0|       8.0|     6.0|0.0|  22|     0|            youtube music|video game music|  16-20|              2-3|2022-08-27|            3|\n",
      "| 21|          1.0|            1| 95.0|                  1|            2|             1|                4|              1|             3|              1|            3|            3|             1|                         2|    5.0|       2.0|     5.0|3.0|  22|    18|                  spotify|           k pop|  21-25|              0-1|2022-08-27|            3|\n",
      "| 19|          6.0|            1| 94.0|                  1|            1|             1|                1|              1|             1|              4|            1|            1|             4|                         1|    2.0|       0.0|     0.0|0.0|  22|    33|                  spotify|            rock|  16-20|              5-6|2022-08-27|            3|\n",
      "| 18|          1.0|            1|155.0|                  2|            2|             2|                2|              2|             2|              1|            3|            3|             3|                         3|    2.0|       2.0|     5.0|1.0|  22|    51|     i do not use a st...|             r&b|  16-20|              0-1|2022-08-27|            3|\n",
      "| 18|          3.0|            1|100.0|                  1|            1|             1|                1|              1|             1|              1|            2|            2|             2|                         1|    7.0|       7.0|     4.0|7.0|  23|     0|                  spotify|         country|  16-20|              2-3|2022-08-27|            2|\n",
      "| 19|          8.0|            1|125.0|                  2|            4|             1|                3|              2|             2|              1|            2|            2|             2|                         2|    1.0|       0.0|     0.0|1.0|  23|     4|            youtube music|             edm|  16-20|              7-8|2022-08-27|            3|\n",
      "| 18|          3.0|            1|100.0|                  2|            2|             1|                4|              1|             4|              1|            3|            3|             2|                         1|    9.0|       3.0|     2.0|7.0|  23|    12|                  spotify|         hip hop|  16-20|              2-3|2022-08-27|            3|\n",
      "| 19|          2.0|            1| 88.0|                  1|            2|             3|                3|              1|             2|              1|            2|            1|             1|                         1|    2.0|       1.0|     2.0|0.0|  23|    16|                  spotify|         country|  16-20|              1-2|2022-08-27|            3|\n",
      "| 18|          4.0|            1|148.0|                  4|            1|             1|                1|              3|             2|              3|            3|            1|             3|                         2|    6.0|       4.0|     7.0|0.0|  23|    19|                  spotify|            jazz|  16-20|              3-4|2022-08-27|            3|\n",
      "| 17|          2.0|            0|100.0|                  2|            1|             1|                3|              2|             2|              2|            4|            2|             3|                         2|    7.0|       5.0|     4.0|1.0|  23|    39|                  spotify|             pop|  16-20|              1-2|2022-08-27|            1|\n",
      "| 16|          8.0|            1|103.0|                  1|            1|             1|                4|              1|             1|              1|            1|            3|             1|                         2|    8.0|       8.0|     4.0|3.0|  23|    39|                  spotify|         hip hop|  16-20|              7-8|2022-08-27|            3|\n",
      "| 16|         12.0|            1|120.0|                  2|            3|             2|                4|              1|             1|              3|            3|            2|             4|                         1|    5.0|       7.0|    10.0|0.0|  23|    40|                  spotify|         hip hop|  16-20|            11-12|2022-08-27|            3|\n",
      "| 15|          3.0|            0|120.0|                  1|            1|             1|                4|              1|             1|              2|            2|            3|             2|                         1|    7.0|       2.0|     0.0|2.0|  23|    43|                  spotify|         hip hop|  11-15|              2-3|2022-08-27|            3|\n",
      "| 15|          8.0|            1|120.0|                  2|            3|             2|                4|              3|             2|              2|            4|            2|             3|                         3|    6.0|       9.0|     3.0|0.0|   0|    28|              apple music|         hip hop|  11-15|              7-8|2022-08-28|            3|\n",
      "+---+-------------+-------------+-----+-------------------+-------------+--------------+-----------------+---------------+--------------+---------------+-------------+-------------+--------------+--------------------------+-------+----------+--------+---+----+------+-------------------------+----------------+-------+-----------------+----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- age: integer (nullable = true)\n",
      " |-- hours_per_day: double (nullable = true)\n",
      " |-- while_working: integer (nullable = true)\n",
      " |-- bpm: double (nullable = true)\n",
      " |-- frequency_classical: integer (nullable = true)\n",
      " |-- frequency_edm: integer (nullable = true)\n",
      " |-- frequency_folk: integer (nullable = true)\n",
      " |-- frequency_hip_hop: integer (nullable = true)\n",
      " |-- frequency_latin: integer (nullable = true)\n",
      " |-- frequency_lofi: integer (nullable = true)\n",
      " |-- frequency_metal: integer (nullable = true)\n",
      " |-- frequency_pop: integer (nullable = true)\n",
      " |-- frequency_r&b: integer (nullable = true)\n",
      " |-- frequency_rock: integer (nullable = true)\n",
      " |-- frequency_video_game_music: integer (nullable = true)\n",
      " |-- anxiety: double (nullable = true)\n",
      " |-- depression: double (nullable = true)\n",
      " |-- insomnia: double (nullable = true)\n",
      " |-- ocd: double (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- minute: integer (nullable = true)\n",
      " |-- primary_streaming_service: string (nullable = true)\n",
      " |-- fav_genre: string (nullable = true)\n",
      " |-- age_bin: string (nullable = true)\n",
      " |-- hours_per_day_bin: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- music_effects: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Concatenate statistics dataframes\n",
    "combined_stats = pd.concat([original_stats, yeojohnson_stats, boxcox_stats], axis=1)\n",
    "\n",
    "# Join the transformed dataframes with the original dataframe\n",
    "combined_transformed_df = extracted_df\n",
    "\n",
    "# Rename columns to remove suffixes\n",
    "for column in numeric_columns:\n",
    "    combined_transformed_df = combined_transformed_df.withColumn(column, col(column))\n",
    "for column in ['hours_per_day', 'bpm']:\n",
    "    combined_transformed_df = combined_transformed_df.withColumn(column, col(column))\n",
    "\n",
    "# Include string columns\n",
    "for column in string_cols:\n",
    "    combined_transformed_df = combined_transformed_df.withColumn(column, col(column))\n",
    "\n",
    "# Show the combined transformed dataframe with the selected columns\n",
    "#combined_transformed_df.show()\n",
    "\n",
    "# Print the schema of the combined transformed dataframe\n",
    "combined_transformed_df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5428bd5",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b445b00f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7521367521367521\n"
     ]
    }
   ],
   "source": [
    "#RandomForest\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Index string columns\n",
    "string_cols = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "\n",
    "# Assemble features into a vector\n",
    "feature_columns = [col for col in combined_transformed_df.columns if col not in string_cols + ['music_effects']]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Define the RandomForest model\n",
    "rf = RandomForestClassifier(labelCol=\"music_effects\", featuresCol=\"features\", numTrees=100)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, rf])\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = combined_transformed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Train the model\n",
    "rf_model = pipeline.fit(train_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = rf_model.transform(test_df)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"music_effects\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Random Forest Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3dce68c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Logistic Regression Accuracy: 0.6581196581196581\n",
      "Shape of coefficient matrix: (4, 113)\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'primary_streaming_service_vec' given input columns: [age, age_bin, anxiety, bpm, date, depression, fav_genre, frequency_classical, frequency_edm, frequency_folk, frequency_hip_hop, frequency_latin, frequency_lofi, frequency_metal, frequency_pop, frequency_r&b, frequency_rock, frequency_video_game_music, hour, hours_per_day, hours_per_day_bin, insomnia, minute, music_effects, ocd, primary_streaming_service, while_working];\n'Project ['primary_streaming_service_vec]\n+- Sample 0.0, 0.8, false, 42\n   +- Sort [age#6581 ASC NULLS FIRST, hours_per_day#7113 ASC NULLS FIRST, while_working#6609 ASC NULLS FIRST, bpm#7141 ASC NULLS FIRST, frequency_classical#6637 ASC NULLS FIRST, frequency_edm#6665 ASC NULLS FIRST, frequency_folk#6693 ASC NULLS FIRST, frequency_hip_hop#6721 ASC NULLS FIRST, frequency_latin#6749 ASC NULLS FIRST, frequency_lofi#6777 ASC NULLS FIRST, frequency_metal#6805 ASC NULLS FIRST, frequency_pop#6833 ASC NULLS FIRST, frequency_r&b#6861 ASC NULLS FIRST, frequency_rock#6889 ASC NULLS FIRST, frequency_video_game_music#6917 ASC NULLS FIRST, anxiety#6945 ASC NULLS FIRST, depression#6973 ASC NULLS FIRST, insomnia#7001 ASC NULLS FIRST, ocd#7029 ASC NULLS FIRST, hour#7057 ASC NULLS FIRST, minute#7085 ASC NULLS FIRST, primary_streaming_service#7169 ASC NULLS FIRST, fav_genre#7197 ASC NULLS FIRST, age_bin#7225 ASC NULLS FIRST, ... 3 more fields], false\n      +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#7197, age_bin#7225, ... 3 more fields]\n         +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#7197, age_bin#7225, ... 3 more fields]\n            +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#7197, age_bin#48 AS age_bin#7225, ... 3 more fields]\n               +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#23 AS fav_genre#7197, age_bin#48, ... 3 more fields]\n                  +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#18 AS primary_streaming_service#7169, fav_genre#23, age_bin#48, ... 3 more fields]\n                     +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#26 AS bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                        +- Project [age#6581, hours_per_day#19 AS hours_per_day#7113, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                           +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#52 AS minute#7085, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                              +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#51 AS hour#7057, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                 +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#46 AS ocd#7029, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                    +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#45 AS insomnia#7001, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                       +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#44 AS depression#6973, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                          +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#43 AS anxiety#6945, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                             +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#42 AS frequency_video_game_music#6917, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#41 AS frequency_rock#6889, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                   +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#39 AS frequency_r&b#6861, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                      +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#38 AS frequency_pop#6833, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                         +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#37 AS frequency_metal#6805, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                            +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#36 AS frequency_lofi#6777, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                               +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#35 AS frequency_latin#6749, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                  +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#32 AS frequency_hip_hop#6721, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                     +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#30 AS frequency_folk#6693, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                        +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#29 AS frequency_edm#6665, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                           +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#27 AS frequency_classical#6637, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                              +- Project [age#6581, hours_per_day#19, while_working#20 AS while_working#6609, bpm#26, frequency_classical#27, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                                 +- Project [age#17 AS age#6581, hours_per_day#19, while_working#20, bpm#26, frequency_classical#27, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                                    +- Project [age#17, hours_per_day#19, while_working#20, bpm#26, frequency_classical#27, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                                       +- Relation [unique_id#16,age#17,primary_streaming_service#18,hours_per_day#19,while_working#20,instrumentalist#21,composer#22,fav_genre#23,exploratory#24,foreign_languages#25,bpm#26,frequency_classical#27,frequency_country#28,frequency_edm#29,frequency_folk#30,frequency_gospel#31,frequency_hip_hop#32,frequency_jazz#33,frequency_k_pop#34,frequency_latin#35,frequency_lofi#36,frequency_metal#37,frequency_pop#38,frequency_r&b#39,... 13 more fields] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     expanded_feature_columns\u001b[38;5;241m.\u001b[39mappend(col)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m string_cols:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# We need to know the actual number of categories for each column\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     one_hot_size \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcol\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_vec\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mhead()[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vec\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msize\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(one_hot_size):\n\u001b[1;32m     53\u001b[0m         expanded_feature_columns\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcol\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_vec_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'primary_streaming_service_vec' given input columns: [age, age_bin, anxiety, bpm, date, depression, fav_genre, frequency_classical, frequency_edm, frequency_folk, frequency_hip_hop, frequency_latin, frequency_lofi, frequency_metal, frequency_pop, frequency_r&b, frequency_rock, frequency_video_game_music, hour, hours_per_day, hours_per_day_bin, insomnia, minute, music_effects, ocd, primary_streaming_service, while_working];\n'Project ['primary_streaming_service_vec]\n+- Sample 0.0, 0.8, false, 42\n   +- Sort [age#6581 ASC NULLS FIRST, hours_per_day#7113 ASC NULLS FIRST, while_working#6609 ASC NULLS FIRST, bpm#7141 ASC NULLS FIRST, frequency_classical#6637 ASC NULLS FIRST, frequency_edm#6665 ASC NULLS FIRST, frequency_folk#6693 ASC NULLS FIRST, frequency_hip_hop#6721 ASC NULLS FIRST, frequency_latin#6749 ASC NULLS FIRST, frequency_lofi#6777 ASC NULLS FIRST, frequency_metal#6805 ASC NULLS FIRST, frequency_pop#6833 ASC NULLS FIRST, frequency_r&b#6861 ASC NULLS FIRST, frequency_rock#6889 ASC NULLS FIRST, frequency_video_game_music#6917 ASC NULLS FIRST, anxiety#6945 ASC NULLS FIRST, depression#6973 ASC NULLS FIRST, insomnia#7001 ASC NULLS FIRST, ocd#7029 ASC NULLS FIRST, hour#7057 ASC NULLS FIRST, minute#7085 ASC NULLS FIRST, primary_streaming_service#7169 ASC NULLS FIRST, fav_genre#7197 ASC NULLS FIRST, age_bin#7225 ASC NULLS FIRST, ... 3 more fields], false\n      +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#7197, age_bin#7225, ... 3 more fields]\n         +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#7197, age_bin#7225, ... 3 more fields]\n            +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#7197, age_bin#48 AS age_bin#7225, ... 3 more fields]\n               +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#7169, fav_genre#23 AS fav_genre#7197, age_bin#48, ... 3 more fields]\n                  +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#18 AS primary_streaming_service#7169, fav_genre#23, age_bin#48, ... 3 more fields]\n                     +- Project [age#6581, hours_per_day#7113, while_working#6609, bpm#26 AS bpm#7141, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                        +- Project [age#6581, hours_per_day#19 AS hours_per_day#7113, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#7085, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                           +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#7057, minute#52 AS minute#7085, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                              +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#7029, hour#51 AS hour#7057, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                 +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#7001, ocd#46 AS ocd#7029, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                    +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#6973, insomnia#45 AS insomnia#7001, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                       +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#6945, depression#44 AS depression#6973, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                          +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#6917, anxiety#43 AS anxiety#6945, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                             +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#6889, frequency_video_game_music#42 AS frequency_video_game_music#6917, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#6861, frequency_rock#41 AS frequency_rock#6889, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                   +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#6833, frequency_r&b#39 AS frequency_r&b#6861, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                      +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#6805, frequency_pop#38 AS frequency_pop#6833, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                         +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#6777, frequency_metal#37 AS frequency_metal#6805, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                            +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#6749, frequency_lofi#36 AS frequency_lofi#6777, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                               +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#6721, frequency_latin#35 AS frequency_latin#6749, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                  +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#6693, frequency_hip_hop#32 AS frequency_hip_hop#6721, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                     +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#6665, frequency_folk#30 AS frequency_folk#6693, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                        +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#6637, frequency_edm#29 AS frequency_edm#6665, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                           +- Project [age#6581, hours_per_day#19, while_working#6609, bpm#26, frequency_classical#27 AS frequency_classical#6637, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                              +- Project [age#6581, hours_per_day#19, while_working#20 AS while_working#6609, bpm#26, frequency_classical#27, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                                 +- Project [age#17 AS age#6581, hours_per_day#19, while_working#20, bpm#26, frequency_classical#27, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                                    +- Project [age#17, hours_per_day#19, while_working#20, bpm#26, frequency_classical#27, frequency_edm#29, frequency_folk#30, frequency_hip_hop#32, frequency_latin#35, frequency_lofi#36, frequency_metal#37, frequency_pop#38, frequency_r&b#39, frequency_rock#41, frequency_video_game_music#42, anxiety#43, depression#44, insomnia#45, ocd#46, hour#51, minute#52, primary_streaming_service#18, fav_genre#23, age_bin#48, ... 3 more fields]\n                                                                                       +- Relation [unique_id#16,age#17,primary_streaming_service#18,hours_per_day#19,while_working#20,instrumentalist#21,composer#22,fav_genre#23,exploratory#24,foreign_languages#25,bpm#26,frequency_classical#27,frequency_country#28,frequency_edm#29,frequency_folk#30,frequency_gospel#31,frequency_hip_hop#32,frequency_jazz#33,frequency_k_pop#34,frequency_latin#35,frequency_lofi#36,frequency_metal#37,frequency_pop#38,frequency_r&b#39,... 13 more fields] csv\n"
     ]
    }
   ],
   "source": [
    "#Multinomnial logistic regression\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# List of feature columns\n",
    "feature_columns = [\"age\", \"hours_per_day\", \"while_working\", \"bpm\", \"frequency_classical\", \n",
    "                   \"frequency_edm\", \"frequency_folk\", \"frequency_hip_hop\", \"frequency_latin\", \n",
    "                   \"frequency_lofi\", \"frequency_metal\", \"frequency_pop\", \"frequency_r&b\", \n",
    "                   \"frequency_rock\", \"frequency_video_game_music\", \"anxiety\", \"depression\", \n",
    "                   \"insomnia\", \"ocd\", \"hour\", \"minute\"]\n",
    "\n",
    "# Index and encode string columns\n",
    "string_cols = ['primary_streaming_service', 'fav_genre', 'age_bin', 'hours_per_day_bin', 'date']\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "encoders = [OneHotEncoder(inputCol=f\"{col}_indexed\", outputCol=f\"{col}_vec\") for col in string_cols]\n",
    "\n",
    "# Assemble all features into a single vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns + [f\"{col}_vec\" for col in string_cols], outputCol=\"features\")\n",
    "# Define the Logistic Regression model\n",
    "lr = LogisticRegression(labelCol=\"music_effects\", featuresCol=\"features\", maxIter=100, family=\"multinomial\")\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=indexers + encoders + [assembler, lr])\n",
    "# Train-test split\n",
    "train_df, test_df = combined_transformed_df.randomSplit([0.8, 0.2], seed=42)\n",
    "# Train the model\n",
    "lr_model = pipeline.fit(train_df)\n",
    "# Make predictions\n",
    "predictions = lr_model.transform(test_df)\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"music_effects\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Multinomial Logistic Regression Accuracy: {accuracy}\")\n",
    "# Extract coefficients and intercepts\n",
    "coefficient_matrix = lr_model.stages[-1].coefficientMatrix\n",
    "intercept_vector = lr_model.stages[-1].interceptVector\n",
    "\n",
    "# Get input columns after one-hot encoding\n",
    "assembler_features = assembler.getInputCols()\n",
    "\n",
    "# Verify the shape of the coefficient matrix\n",
    "print(f\"Shape of coefficient matrix: {coefficient_matrix.toArray().shape}\")\n",
    "\n",
    "# Create a list of feature names\n",
    "expanded_feature_columns = []\n",
    "for col in feature_columns:\n",
    "    expanded_feature_columns.append(col)\n",
    "for col in string_cols:\n",
    "    # We need to know the actual number of categories for each column\n",
    "    one_hot_size = train_df.select(f\"{col}_vec\").head()[f\"{col}_vec\"].size\n",
    "    for i in range(one_hot_size):\n",
    "        expanded_feature_columns.append(f\"{col}_vec_{i}\")\n",
    "# Verify the length of expanded feature columns\n",
    "print(f\"Number of expanded feature columns: {len(expanded_feature_columns)}\")\n",
    "# Ensure the number of columns match\n",
    "assert coefficient_matrix.toArray().shape[1] == len(expanded_feature_columns)\n",
    "# Create DataFrame of coefficients for each feature and each class\n",
    "coefficients_df = pd.DataFrame(coefficient_matrix.toArray(), columns=expanded_feature_columns)\n",
    "coefficients_df['class'] = range(coefficient_matrix.toArray().shape[0])\n",
    "coefficients_df = coefficients_df.melt(id_vars=['class'], var_name='Feature', value_name='Coefficient')\n",
    "\n",
    "print(\"Feature Coefficients:\")\n",
    "print(coefficients_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c308a8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /home/ubuntu/.local/lib/python3.10/site-packages (1.5.0)\n",
      "Requirement already satisfied: xgboost in /home/ubuntu/.local/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn) (1.22.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/ubuntu/.local/lib/python3.10/site-packages (from scikit-learn) (1.8.1)\n"
     ]
    }
   ],
   "source": [
    "# !pip install xgboost\n",
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "61f9b7ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o13320.fit.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1512)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:103)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.doExecute(ObjectHashAggregateExec.scala:88)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)\n\tat org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)\n\tat org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)\n\tat org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:172)\n\tat org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:256)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:254)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:254)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:226)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:365)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:338)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2971)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:2971)\n\tat org.apache.spark.ml.feature.StringIndexer.countByValue(StringIndexer.scala:204)\n\tat org.apache.spark.ml.feature.StringIndexer.sortByFreq(StringIndexer.scala:212)\n\tat org.apache.spark.ml.feature.StringIndexer.fit(StringIndexer.scala:242)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39mindexers \u001b[38;5;241m+\u001b[39m [assembler, kmeans])\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m kmeans_model \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_transformed_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m     23\u001b[0m predictions \u001b[38;5;241m=\u001b[39m kmeans_model\u001b[38;5;241m.\u001b[39mtransform(combined_transformed_df)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/pipeline.py:114\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    112\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    115\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/base.py:161\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params))\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py:335\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset):\n\u001b[0;32m--> 335\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    336\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    337\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/ml/wrapper.py:332\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03mFits a Java model to the input dataset.\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;124;03m    fitted Java model\u001b[39;00m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 332\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o13320.fit.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1512)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:103)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.aggregate.ObjectHashAggregateExec.doExecute(ObjectHashAggregateExec.scala:88)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD$lzycompute(ShuffleExchangeExec.scala:135)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.inputRDD(ShuffleExchangeExec.scala:135)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture$lzycompute(ShuffleExchangeExec.scala:140)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.mapOutputStatisticsFuture(ShuffleExchangeExec.scala:139)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.$anonfun$submitShuffleJob$1(ShuffleExchangeExec.scala:68)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob(ShuffleExchangeExec.scala:68)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeLike.submitShuffleJob$(ShuffleExchangeExec.scala:67)\n\tat org.apache.spark.sql.execution.exchange.ShuffleExchangeExec.submitShuffleJob(ShuffleExchangeExec.scala:115)\n\tat org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture$lzycompute(QueryStageExec.scala:170)\n\tat org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.shuffleFuture(QueryStageExec.scala:170)\n\tat org.apache.spark.sql.execution.adaptive.ShuffleQueryStageExec.doMaterialize(QueryStageExec.scala:172)\n\tat org.apache.spark.sql.execution.adaptive.QueryStageExec.materialize(QueryStageExec.scala:82)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5(AdaptiveSparkPlanExec.scala:256)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$5$adapted(AdaptiveSparkPlanExec.scala:254)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat scala.collection.IterableLike.foreach(IterableLike.scala:74)\n\tat scala.collection.IterableLike.foreach$(IterableLike.scala:73)\n\tat scala.collection.AbstractIterable.foreach(Iterable.scala:56)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.$anonfun$getFinalPhysicalPlan$1(AdaptiveSparkPlanExec.scala:254)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.getFinalPhysicalPlan(AdaptiveSparkPlanExec.scala:226)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.withFinalPlanUpdate(AdaptiveSparkPlanExec.scala:365)\n\tat org.apache.spark.sql.execution.adaptive.AdaptiveSparkPlanExec.executeCollect(AdaptiveSparkPlanExec.scala:338)\n\tat org.apache.spark.sql.Dataset.collectFromPlan(Dataset.scala:3715)\n\tat org.apache.spark.sql.Dataset.$anonfun$collect$1(Dataset.scala:2971)\n\tat org.apache.spark.sql.Dataset.$anonfun$withAction$1(Dataset.scala:3706)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$5(SQLExecution.scala:103)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:163)\n\tat org.apache.spark.sql.execution.SQLExecution$.$anonfun$withNewExecutionId$1(SQLExecution.scala:90)\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:775)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:64)\n\tat org.apache.spark.sql.Dataset.withAction(Dataset.scala:3704)\n\tat org.apache.spark.sql.Dataset.collect(Dataset.scala:2971)\n\tat org.apache.spark.ml.feature.StringIndexer.countByValue(StringIndexer.scala:204)\n\tat org.apache.spark.ml.feature.StringIndexer.sortByFreq(StringIndexer.scala:212)\n\tat org.apache.spark.ml.feature.StringIndexer.fit(StringIndexer.scala:242)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "#Kmeans clustering \n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "# Index string columns\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=f\"{col}_indexed\", handleInvalid='keep') for col in string_cols]\n",
    "\n",
    "# Assemble features into a vector\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "\n",
    "# Define the KMeans model\n",
    "kmeans = KMeans(featuresCol=\"features\", k=3)\n",
    "\n",
    "# Create the pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, kmeans])\n",
    "\n",
    "# Train the model\n",
    "kmeans_model = pipeline.fit(combined_transformed_df)\n",
    "\n",
    "# Make predictions\n",
    "predictions = kmeans_model.transform(combined_transformed_df)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(f\"K-Means Silhouette Score: {silhouette}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3efdfec6",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o13318.javaToPython.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1512)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:103)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:340)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:185)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:184)\n\tat org.apache.spark.sql.Dataset.javaToPython(Dataset.scala:3529)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Extract features and predictions\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfeatures\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mfeatures\u001b[38;5;241m.\u001b[39mtoArray())\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      5\u001b[0m pred_labels \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mrdd\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m row: row\u001b[38;5;241m.\u001b[39mprediction)\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot clusters\u001b[39;00m\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py:86\u001b[0m, in \u001b[0;36mDataFrame.rdd\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the content as an :class:`pyspark.RDD` of :class:`Row`.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_rdd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 86\u001b[0m     jrdd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjavaToPython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_rdd \u001b[38;5;241m=\u001b[39m RDD(jrdd, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx\u001b[38;5;241m.\u001b[39m_sc, BatchedSerializer(PickleSerializer()))\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_rdd\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/pyspark/sql/utils.py:111\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 111\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m py4j\u001b[38;5;241m.\u001b[39mprotocol\u001b[38;5;241m.\u001b[39mPy4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    113\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/spark-3.2.1-bin-hadoop2.7/python/lib/py4j-0.10.9.3-src.zip/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o13318.javaToPython.\n: java.lang.IllegalStateException: Cannot call methods on a stopped SparkContext.\nThis stopped SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n\nThe currently active SparkContext was created at:\n\norg.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\njava.base/jdk.internal.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\njava.base/jdk.internal.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\njava.base/java.lang.reflect.Constructor.newInstance(Constructor.java:490)\npy4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\npy4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\npy4j.Gateway.invoke(Gateway.java:238)\npy4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\npy4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\npy4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\npy4j.ClientServerConnection.run(ClientServerConnection.java:106)\njava.base/java.lang.Thread.run(Thread.java:829)\n         \n\tat org.apache.spark.SparkContext.assertNotStopped(SparkContext.scala:118)\n\tat org.apache.spark.SparkContext.broadcast(SparkContext.scala:1512)\n\tat org.apache.spark.sql.execution.datasources.csv.CSVFileFormat.buildReader(CSVFileFormat.scala:103)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues(FileFormat.scala:131)\n\tat org.apache.spark.sql.execution.datasources.FileFormat.buildReaderWithPartitionValues$(FileFormat.scala:122)\n\tat org.apache.spark.sql.execution.datasources.TextBasedFileFormat.buildReaderWithPartitionValues(FileFormat.scala:177)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD$lzycompute(DataSourceScanExec.scala:426)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.inputRDD(DataSourceScanExec.scala:417)\n\tat org.apache.spark.sql.execution.FileSourceScanExec.doExecute(DataSourceScanExec.scala:504)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDD(WholeStageCodegenExec.scala:526)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs(WholeStageCodegenExec.scala:454)\n\tat org.apache.spark.sql.execution.InputRDDCodegen.inputRDDs$(WholeStageCodegenExec.scala:453)\n\tat org.apache.spark.sql.execution.InputAdapter.inputRDDs(WholeStageCodegenExec.scala:497)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.SortExec.inputRDDs(SortExec.scala:132)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.SampleExec.inputRDDs(basicPhysicalOperators.scala:340)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.ProjectExec.inputRDDs(basicPhysicalOperators.scala:50)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec.doExecute(WholeStageCodegenExec.scala:750)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$execute$1(SparkPlan.scala:184)\n\tat org.apache.spark.sql.execution.SparkPlan.$anonfun$executeQuery$1(SparkPlan.scala:222)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:219)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:180)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:185)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:184)\n\tat org.apache.spark.sql.Dataset.javaToPython(Dataset.scala:3529)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract features and predictions\n",
    "features = predictions.select(\"features\").rdd.map(lambda row: row.features.toArray()).collect()\n",
    "pred_labels = predictions.select(\"prediction\").rdd.map(lambda row: row.prediction).collect()\n",
    "\n",
    "# Plot clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "for i in range(len(features)):\n",
    "    plt.scatter(features[i][0], features[i][1], c=pred_labels[i], cmap='viridis')\n",
    "\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.title(\"KMeans Clustering\")\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59367b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
